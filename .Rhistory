only_var[i,][which(is.na(only_var[i,]))] <- ""
}
tmp_df <- cbind(only_var, stats)
tmp_df$logLik <- round(tmp_df$logLik, 1)
tmp_df$AICc <- round(tmp_df$AICc, 1)
tmp_df$delta <- round(tmp_df$delta, 2)
tmp_df$weight <- round(tmp_df$weight, 2)
rownames(tmp_df) <- paste0("model ", 1:nrow(tmp_df))
return(tmp_df)
}
# Tree
tree <- read.tree("tree/myrtales_pruned.tre")
# Master table
master_table <- readRDS("datasets/Myrtales_full_dataset.Rdata")
############################################
# Building global model for diversification (div rates as dependent variable)
# here note that we're keeping only CHELSA_bio10_17 and CHELSA_bio10_11 for
# precipitation and temperature
master_table <- subset(master_table, !is.na(master_table$most_common_life_form))
master_table <- subset(master_table, !is.na(master_table$fm_scoring_fruit))
master_table <- subset(master_table, !is.na(master_table$seed.length.mean))
master_table <- subset(master_table, !is.na(master_table$fm_scoring_seed_number))
master_table <- subset(master_table, !is.na(master_table$fm_scoring_corolla_diam))
model_div_full <- phylolm(div_rate_eps0.9~
most_common_life_form+
fm_scoring_fruit+
seed.length.mean+
fm_scoring_seed_number+
fm_scoring_corolla_diam+
CHELSA_bio10_11+
CHELSA_bio10_02+
CHELSA_bio10_17+
GLOBAL_SLOPE_10MIN+
depthtobedrock2+
meanwatercap+
meancarbon+
meanpH, data=master_table, phy=tree)
# Dredging full model for "best" combinations
dredge_div <- dredge(model_div_full)
warnings()
write.csv(dredge_div, file="results/h2/dredged_divrate_full.csv", row.names=F)
#----
dredge_div <- read.csv("results/h2/dredged_divrate_full.csv")
dredge_div <- organize.table(dredge_div)
dredge_div <- get.rqrs(organized_table=dredge_div, full_dataset=master_table, phy=tree, dep.var="div_rate_eps0.9")
write.csv(dredge_div, file="results/h2/dredged_divrate_organized_table.csv")
dredge_div
############################################
############################################
# Building global model for niche breadth (niche breadth  as dependent variable)
model_vol_full <- phylolm(niche_through_time~
most_common_life_form+
fm_scoring_fruit+
seed.length.mean+
fm_scoring_seed_number+
fm_scoring_corolla_diam+
CHELSA_bio10_11+
CHELSA_bio10_02+
CHELSA_bio10_17+
GLOBAL_SLOPE_10MIN+
depthtobedrock2+
meanwatercap+
meancarbon+
meanpH
, data=master_table, phy=tree)
# Dredging full model for "best" combinations
dredge_vol <- dredge(model_vol_full)
write.csv(dredge_vol, file="results/h2/dredged_niche_full.csv", row.names=F)
#----
dredge_vol <- read.csv("results/h2/dredged_niche_full.csv")
dredge_vol <- organize.table(dredge_vol)
dredge_vol <- get.rqrs(organized_table=dredge_vol, full_dataset=master_table, phy=tree, dep.var="niche_through_time")
write.csv(dredge_vol, file="results/h2/dredge_niche_organized_table.csv")
rm(list=ls())
# Regression analyses 2: Dredging models
# rm(list=ls())
setwd("~/Desktop/WCVP_special_issue/Eve_MyrtalesPAFTOL/myrtales")
#################################################################################################
library(phylolm)
library(ape)
library(phytools)
library(MuMIn)
# Functions to get r squares and to organize results
get.rqrs <- function(organized_table, full_dataset, phy, dep.var="div_rate_eps0.9") {
vars <- setdiff(colnames(organized_table),c("df","logLik","AICc","delta","weight"))
only_var <- organized_table[,vars]
colnames(full_dataset)[which(colnames(full_dataset)==dep.var)] <- "focal_var"
rqsrs <- c()
for(i in 1:nrow(organized_table)) {
to_include_in_model <- colnames(only_var)[which(only_var[i,] != "")]
tmp_dataset <- full_dataset[c("focal_var", to_include_in_model)]
model <- phylolm(focal_var~.,data=tmp_dataset, phy=tree)
rqsrs[i] <- round(model$r.squared,3)
}
organized_table$rsqs <- rqsrs
return(organized_table)
}
organize.table <- function(table_results) {
subset_best_fit <- subset(table_results, table_results$delta < 2)
subset_best_fit <- subset_best_fit[,-1]
vars <- setdiff(colnames(subset_best_fit),c("df","logLik","AICc","delta","weight"))
only_var <- subset_best_fit[,vars]
stats <- subset_best_fit[,c("df","logLik","AICc","delta","weight")]
for(i in 1:nrow(only_var)) {
only_var[i,][which(!is.na(only_var[i,]))] <- "x"
only_var[i,][which(is.na(only_var[i,]))] <- ""
}
tmp_df <- cbind(only_var, stats)
tmp_df$logLik <- round(tmp_df$logLik, 1)
tmp_df$AICc <- round(tmp_df$AICc, 1)
tmp_df$delta <- round(tmp_df$delta, 2)
tmp_df$weight <- round(tmp_df$weight, 2)
rownames(tmp_df) <- paste0("model ", 1:nrow(tmp_df))
return(tmp_df)
}
# Tree
tree <- read.tree("tree/myrtales_pruned.tre")
# Master table
master_table <- readRDS("datasets/Myrtales_full_dataset.Rdata")
############################################
# Building global model for diversification (div rates as dependent variable)
# here note that we're keeping only CHELSA_bio10_17 and CHELSA_bio10_11 for
# precipitation and temperature
master_table <- subset(master_table, !is.na(master_table$most_common_life_form))
master_table <- subset(master_table, !is.na(master_table$fm_scoring_fruit))
master_table <- subset(master_table, !is.na(master_table$seed.length.mean))
master_table <- subset(master_table, !is.na(master_table$fm_scoring_seed_number))
master_table <- subset(master_table, !is.na(master_table$fm_scoring_corolla_diam))
model_div_full <- phylolm(div_rate_eps0.9~
most_common_life_form+
fm_scoring_fruit+
seed.length.mean+
fm_scoring_seed_number+
fm_scoring_corolla_diam+
CHELSA_bio10_11+
CHELSA_bio10_02+
CHELSA_bio10_17+
GLOBAL_SLOPE_10MIN+
depthtobedrock2+
meanwatercap+
meancarbon+
meanpH, data=master_table, phy=tree)
# Dredging full model for "best" combinations
dredge_div <- dredge(model_div_full)
organize.table <- function(table_results, thrsh=T) {
if(thrsh) {
subset_best_fit <- subset(table_results, table_results$delta < 2)
} else {
subset_best_fit <- table_results
}
subset_best_fit <- subset_best_fit[,-1]
vars <- setdiff(colnames(subset_best_fit),c("df","logLik","AICc","delta","weight"))
only_var <- subset_best_fit[,vars]
stats <- subset_best_fit[,c("df","logLik","AICc","delta","weight")]
for(i in 1:nrow(only_var)) {
only_var[i,][which(!is.na(only_var[i,]))] <- "x"
only_var[i,][which(is.na(only_var[i,]))] <- ""
}
tmp_df <- cbind(only_var, stats)
tmp_df$logLik <- round(tmp_df$logLik, 1)
tmp_df$AICc <- round(tmp_df$AICc, 1)
tmp_df$delta <- round(tmp_df$delta, 2)
tmp_df$weight <- round(tmp_df$weight, 2)
rownames(tmp_df) <- paste0("model ", 1:nrow(tmp_df))
return(tmp_df)
}
subset_best_fit <- subset(table_results, table_results$delta < 2)
organize.table <- function(table_results, thrsh=T) {
if(thrsh) {
subset_best_fit <- subset(table_results, table_results$delta < 2)
} else {
subset_best_fit <- table_results
}
subset_best_fit <- subset_best_fit[,-1]
vars <- setdiff(colnames(subset_best_fit),c("df","logLik","AICc","delta","weight"))
only_var <- subset_best_fit[,vars]
stats <- subset_best_fit[,c("df","logLik","AICc","delta","weight")]
for(i in 1:nrow(only_var)) {
only_var[i,][which(!is.na(only_var[i,]))] <- "x"
only_var[i,][which(is.na(only_var[i,]))] <- ""
}
tmp_df <- cbind(only_var, stats)
tmp_df$logLik <- round(tmp_df$logLik, 1)
tmp_df$AICc <- round(tmp_df$AICc, 1)
tmp_df$delta <- round(tmp_df$delta, 2)
tmp_df$weight <- round(tmp_df$weight, 2)
rownames(tmp_df) <- paste0("model ", 1:nrow(tmp_df))
return(tmp_df)
}
#----
dredge_div <- read.csv("results/h2/dredged_divrate_full.csv")
dredge_div <- organize.table(dredge_div, thrsh=F)
# Functions to get r squares and to organize results
get.rqrs <- function(organized_table, full_dataset, phy, dep.var="div_rate_eps0.9") {
vars <- setdiff(colnames(organized_table),c("df","logLik","AICc","delta","weight"))
only_var <- organized_table[,vars]
colnames(full_dataset)[which(colnames(full_dataset)==dep.var)] <- "focal_var"
rqsrs <- c()
for(i in 1:nrow(organized_table)) {
to_include_in_model <- colnames(only_var)[which(only_var[i,] != "")]
tmp_dataset <- full_dataset[c("focal_var", to_include_in_model)]
model <- phylolm(focal_var~.,data=tmp_dataset, phy=tree)
rqsrs[i] <- round(model$r.squared,3)
cat(i,"\r")
}
organized_table$rsqs <- rqsrs
return(organized_table)
}
organize.table <- function(table_results, thrsh=T) {
if(thrsh) {
subset_best_fit <- subset(table_results, table_results$delta < 2)
} else {
subset_best_fit <- table_results
}
subset_best_fit <- subset_best_fit[,-1]
vars <- setdiff(colnames(subset_best_fit),c("df","logLik","AICc","delta","weight"))
only_var <- subset_best_fit[,vars]
stats <- subset_best_fit[,c("df","logLik","AICc","delta","weight")]
for(i in 1:nrow(only_var)) {
only_var[i,][which(!is.na(only_var[i,]))] <- "x"
only_var[i,][which(is.na(only_var[i,]))] <- ""
}
tmp_df <- cbind(only_var, stats)
tmp_df$logLik <- round(tmp_df$logLik, 1)
tmp_df$AICc <- round(tmp_df$AICc, 1)
tmp_df$delta <- round(tmp_df$delta, 2)
tmp_df$weight <- round(tmp_df$weight, 2)
rownames(tmp_df) <- paste0("model ", 1:nrow(tmp_df))
cat(i,"\r")
return(tmp_df)
}
dredge_div
dredge_div <- get.rqrs(organized_table=dredge_div, full_dataset=master_table, phy=tree, dep.var="div_rate_eps0.9")
dredge_div
max(dredge_div$rsqs)
dredge_div[order(dredge_div$rsqs),]
?order
dredge_div[order(dredge_div$rsqs),decreasing = T]
dredge_div[order(dredge_div$rsqs,decreasing = T),]
rm(list=ls())
# rm(list=ls())
library(dplyr)
# function to filter dubious ids from gbif data according to what the wcvp says about their distribution
FilterWCVP <- function(points, all_vars, reference_table, twgd_data, lon="decimalLongitude", lat="decimalLatitude") {
npoints_start <- nrow(points)
tmp_points = as.data.frame(points)
colnames(tmp_points)[colnames(tmp_points)==lon] <- "x"
colnames(tmp_points)[colnames(tmp_points)==lat] <- "y"
tmp_points = subset(tmp_points, !is.na(tmp_points$x))
tmp_points = subset(tmp_points, !is.na(tmp_points$y))
# Load shape files and make sure they have the same name as the WCVP column with the TDWG areas
# twgd_data <- suppressWarnings(maptools::readShapeSpatial(path))
dubiousGBIF_ids <- c()
for(species_index in 1:nrow(reference_table)) {
gbif_subset <- subset(tmp_points, tmp_points$scientificName == reference_table$gbif_name[species_index])
if(nrow(gbif_subset)!=0) {
wcvp_subset <- subset(all_vars, all_vars$taxon_name == reference_table$wcvp_name[species_index])
wcvp_subset <- subset(wcvp_subset, wcvp_subset$introduced==0)
wcvp_subset <- subset(wcvp_subset, wcvp_subset$extinct==0)
wcvp_subset <- subset(wcvp_subset, wcvp_subset$location_doubtful==0)
occ_areas <- wcvp_subset$area_code_l3
area_plus_buffer <- twgd_data[which(as.character(twgd_data$LEVEL3_COD) %in% occ_areas),]
if(nrow(area_plus_buffer)>0) {
coords <- gbif_subset[,c("x","y")]
sp::coordinates(coords) <- ~ x + y
answer <- which(is.na(sp::over(coords, area_plus_buffer)[,3]))
if(length(answer) != 0) {
dubiousGBIF_ids <- c(dubiousGBIF_ids, as.character(gbif_subset$gbifID[answer]))
}
}
}
cat(species_index, "\r")
}
cleaned_points <- subset(points, !as.character(points$gbifID) %in% dubiousGBIF_ids)
npoints_end <- nrow(cleaned_points)
print(paste0(npoints_start - npoints_end, " points removed."))
return(cleaned_points)
}
# function to deal with a bug in how taxize treats authors names
fix.names.taxize <- function(focal_species_trees) {
for(name_index in 1:length(focal_species_trees)){
one_tmp_string <- focal_species_trees[name_index]
if(any(grepl("[()]", one_tmp_string))){
splitted_names <- strsplit(one_tmp_string," ")[[1]]
begin_author <- which(grepl("[()]", splitted_names))[1]
species_name <- paste0(splitted_names[1:(begin_author-1)], collapse=" ")
author <- splitted_names[begin_author:length(splitted_names)]
old_authors <- author[grep("[()]", author)]
end_first_half <- floor(length(old_authors)/2)
before <- old_authors[1:end_first_half]
after <- old_authors[(end_first_half+1):(length(old_authors))]
if(paste(before,collapse = " ") == paste(after, collapse=" ")) {
author <- paste(author[1:(length(author)/2)], collapse=" ")
focal_species_trees[name_index] <- paste0(species_name, " ", author, collapse=" ")
} else {
author <- paste(author, collapse=" ")
focal_species_trees[name_index] <- paste0(species_name, " ", author, collapse=" ")
}
}
}
return(focal_species_trees)
}
# A way to simplify names in table and trees so that species names match again
simplify.names.taxize <- function(names) {
results <- c()
for(name_index in 1:length(names)){
one_tmp_string <- names[name_index]
splitted_names <- strsplit(one_tmp_string," ")[[1]]
genus <- splitted_names[1]
epiphet <- splitted_names[2]
if(is.na(epiphet)) {
full_name <- "tip_to_drop" # indet species
} else {
if(any(grepl("indet_sp",splitted_names))) {
full_name <- "tip_to_drop" # indet species
} else {
if(stringr::str_detect(epiphet,"[[:upper:]]")) {
full_name <- "tip_to_drop" # indet species
} else {
if(length(splitted_names) > 2) {
complement <- splitted_names[3:length(splitted_names)]
if(grepl("[()]", complement[1])) {
full_name <- paste(c(genus, epiphet), collapse = " ")
} else {
if(stringr::str_detect(complement[1],"[[:upper:]]")) {
full_name <- paste(c(genus, epiphet), collapse = " ")
} else {
complement <- subset(complement, !stringr::str_detect(complement,"[[:upper:]]"))
complement <- subset(complement, !grepl(paste(c("[()]","&","([0-9]+).*$","^ex$"), collapse="|"), complement))
if(length(complement)==0){
full_name <- paste(c(genus, epiphet), collapse = " ")
} else {
full_name <- paste(c(genus, epiphet, complement), collapse = " ")
}
}
}
}
}
}
}
results[name_index] <- full_name
}
return(results)
}
#-----------------------------
# load wcvp data
dist_sample <- read.table("C:/Users/patri/Desktop/temp/wcvp_names_and_distribution_special_edition_2022/wcvp_distribution.txt", sep="|", header=TRUE, quote = "", fill=TRUE, encoding = "UTF-8")
# load wcvp data
dist_sample <- read.table("../../wcvp_names_and_distribution_special_edition_2022/wcvp_distribution.txt", sep="|", header=TRUE, quote = "", fill=TRUE, encoding = "UTF-8")
names_sample <- read.table("../../wcvp_names_and_distribution_special_edition_2022/wcvp_names.txt", sep="|", header=TRUE, quote = "", fill=TRUE, encoding = "UTF-8")
setwd("~/Desktop/WCVP_special_issue/Patricia_Climbers/climbers")
#-----------------------------
# Merge them in one big table
all_vars <- merge(dist_sample, names_sample, by="plant_name_id")
# reference table for taxized names
#-----------------------------
reference_table <- read.csv("taxized_reference_table.csv")
length(unique(reference_table$wcvp_name))
length(unique(reference_table$gbif_name))
##################################
##################################
# A ideia aqui e' ver quantas especies a gente perde se usar o filtro do wcvp no arquivo com os
# pontos que a gente tinha baixado antes
library(data.table)
# reference table for taxized names
#-----------------------------
reference_table <- read.csv("taxized_reference_table.csv")
gbif_data <- fread("full_gbif_quest/neotropics_tracheophyte_filtered_gbif.csv") # load  GBIF
# subgbif<-gbif_data[1:100000,]
length(unique(gbif_data$scientificName))
gbif_data <- as.data.frame(gbif_data)[,c(2:4)]
colnames(gbif_data)[1] <- "scientificName"
# subgbif<-gbif_data[1:100000,]
length(unique(gbif_data$scientificName))
library(stringr)
reference_table2<-reference_table
cleaned_points3<-cleaned_points
reference_table2
cleaned_points2<-gbif_data
reference_table2<-reference_table
reference_table2$gbif_name<-simplify.names.taxize(reference_table2$gbif_name)
reference_table2<-subset(reference_table2, gbif_name!="tip_to_drop")
cleaned_points2$scientificName<-simplify.names.taxize(cleaned_points2$scientificName)
path="/Users/thaisvasconcelos/Desktop/WCVP_special_issue/WCVPtools/wgsrpd-master/level3/level3.shp"
twgd_data <- suppressWarnings(maptools::readShapeSpatial(path))
subset_reference_table2 <- subset(reference_table2, reference_table2$gbif_name %in% unique(cleaned_points2$scientificName))
subset_reference_table2
reference_table2$gbif_name
unique(cleaned_points2$scientificName)
subset_reference_table2
subset_reference_table2 <- subset(reference_table2, !reference_table2$gbif_name %in% unique(cleaned_points2$scientificName))
subset_reference_table2 <- subset(reference_table2, reference_table2$gbif_name %in% unique(cleaned_points2$scientificName))
unique(cleaned_points2$scientificName) %in% reference_table2$gbif_name
unique(cleaned_points2$scientificName)[!which(unique(cleaned_points2$scientificName) %in% reference_table2$gbif_name)]
unique(cleaned_points2$scientificName)[which(unique(cleaned_points2$scientificName) %in% reference_table2$gbif_name)]
unique(cleaned_points2$scientificName)
reference_table2$gbif_name)
reference_table2$gbif_name
x<-unique(cleaned_points2$scientificName)
unique(cleaned_points2$scientificName)[which(!x %in% reference_table2$gbif_name)]
grep("Schefflera", reference_table2$gbif_name)
grep("Schefflera trianae", reference_table2$gbif_name)
grep("Schefflera trian", reference_table2$gbif_name)
grep("Schefflera trian*", reference_table2$gbif_name)
grep("Schefflera", reference_table2$gbif_name)
reference_table2$gbif_name[grep("Schefflera", reference_table2$gbif_name)]
reference_table2
unique(cleaned_points2$scientificName)[which(!x %in% reference_table2$gbif_name)]
reference_table2$gbif_name[grep("Schefflera", reference_table2$wcvp_name)]
reference_table2$gbif_name[grep("Schefflera triana", reference_table2$wcvp_name)]
unique(cleaned_points2$scientificName)[which(!x %in% reference_table2$gbif_name)]
reference_table2$gbif_name[grep("Schefflera trianae", reference_table2$gbif_name)]
reference_table2$gbif_name
reference_table2
reference_table2$gbif_name<-simplify.names.taxize(reference_table2$gbif_name)
reference_table2<-reference_table
reference_table2$gbif_name<-simplify.names.taxize(reference_table2$gbif_name)
reference_table2
reference_table2$gbif_name[grep("Schefflera", reference_table2$gbif_name)]
sort(reference_table2$gbif_name[grep("Schefflera", reference_table2$gbif_name)])
sort(reference_table2$wcvp_name[grep("Schefflera", reference_table2$wcvp_name)])
unique(cleaned_points2$scientificName)[which(!x %in% reference_table2$gbif_name)]
subset_reference_table2
subset_reference_table2
subset_all_vars <- subset(all_vars, all_vars$taxon_name %in% subset_reference_table2$wcvp_name)
npoints_start <- nrow(cleaned_points)
npoints_start <- nrow(cleaned_points2)
npoints_start
tmp_points = as.data.frame(cleaned_points2)
colnames(tmp_points)[colnames(tmp_points)=="lon"] <- "x"
colnames(tmp_points)[colnames(tmp_points)=="lat"] <- "y"
colnames(tmp_points)
tmp_points = subset(tmp_points, !is.na(tmp_points$x))
tmp_points = subset(tmp_points, !is.na(tmp_points$y))
# Load shape files and make sure they have the same name as the WCVP column with the TDWG areas
# twgd_data <- suppressWarnings(maptools::readShapeSpatial(path))
cleaned_points<-vector("list",nrow(subset_reference_table2))
excluded_spp<-c(length(nrow(subset_reference_table2)))
excluded_spp
cleaned_points
tmp_points
species_index=1
all_spp <- unique(tmp_points$scientificName)
all_spp
all_spp
gbif_subset <- subset(tmp_points, tmp_points$scientificName == all_spp[species_index])
gbif_subset
filtered_points <- as.data.frame(matrix(nrow=0,ncol=3))
filtered_points
colnames(tmp_points)
colnames(filtered_points) <- colnames(tmp_points)
filtered_points
filtered_points
all_spp[species_index]
all_spp[species_index] %in% subset_reference_table$gbif_name
all_spp[species_index] %in% subset_reference_table2$gbif_name
gbif_subset
all_spp[species_index] %in% subset_reference_table2$gbif_name
all_vars$taxon_name
all_spp[species_index] %in% subset_reference_table2$wcvp_name
gbif_subset <- subset(tmp_points, tmp_points$scientificName == all_spp[species_index])
wcvp_subset <- subset(all_vars, all_vars$taxon_name == all_spp[species_index]) # aqui usa o wcvp names
wcvp_subset
wcvp_subset <- subset(wcvp_subset, wcvp_subset$introduced==0)
wcvp_subset <- subset(wcvp_subset, wcvp_subset$extinct==0)
wcvp_subset <- subset(wcvp_subset, wcvp_subset$location_doubtful==0)
occ_areas <- wcvp_subset$area_code_l3
occ_areas
area_plus_buffer <- twgd_data[which(as.character(twgd_data$LEVEL3_COD) %in% occ_areas),]
nrow(area_plus_buffer)>0)
(nrow(area_plus_buffer)>0
)
coords <- gbif_subset[,c("x","y")]
coords
sp::coordinates(coords) <- ~ x + y
answer <- which(is.na(sp::over(coords, area_plus_buffer)[,3])) # coord (x) s?o os pontos, area_plus_buffer (y) ? a ?rea de ocorrencia segundo o POWO
answer
over(coords, area_plus_buffer)
sp::over(coords, area_plus_buffer)
answer
filtered_points <- as.data.frame(matrix(nrow=0,ncol=3))
colnames(filtered_points) <- colnames(tmp_points)
for(species_index in 1:length(all_spp)) {
if(all_spp[species_index] %in% subset_reference_table2$wcvp_name) { # if name exists in WCVP database, filter distribution according to the twdg
gbif_subset <- subset(tmp_points, tmp_points$scientificName == all_spp[species_index])
if(nrow(gbif_subset)!=0) {
wcvp_subset <- subset(all_vars, all_vars$taxon_name == all_spp[species_index]) # aqui usa o wcvp names
wcvp_subset <- subset(wcvp_subset, wcvp_subset$introduced==0)
wcvp_subset <- subset(wcvp_subset, wcvp_subset$extinct==0)
wcvp_subset <- subset(wcvp_subset, wcvp_subset$location_doubtful==0)
occ_areas <- wcvp_subset$area_code_l3
area_plus_buffer <- twgd_data[which(as.character(twgd_data$LEVEL3_COD) %in% occ_areas),]
if(nrow(area_plus_buffer)>0) {
coords <- gbif_subset[,c("x","y")]
sp::coordinates(coords) <- ~ x + y
answer <- which(is.na(sp::over(coords, area_plus_buffer)[,3])) # coord (x) s?o os pontos, area_plus_buffer (y) ? a ?rea de ocorrencia segundo o POWO
if(length(answer) != 0) {
filtered_gbif_subset <- gbif_subset[-answer,]
filtered_points <- rbind(filtered_points, filtered_gbif_subset)
#dubiousGBIF_ids <- c(dubiousGBIF_ids, as.character(gbif_subset$gbifID[answer]))
}
if(length(answer) == 0) {
filtered_points <- rbind(filtered_points, gbif_subset)
}
}
}
} else { # else, just keep same points
gbif_subset <- subset(tmp_points, tmp_points$scientificName == all_spp[species_index])
filtered_points <- rbind(filtered_points, gbif_subset)
}
cat(species_index, "\r")
}
